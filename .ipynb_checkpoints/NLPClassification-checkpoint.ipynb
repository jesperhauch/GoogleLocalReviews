{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.sparse import hstack, vstack, coo_matrix, csr_matrix, bmat\n",
    "sns.set_style(\"darkgrid\")\n",
    "data_path = \"data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build models with:\n",
    "- BoW or tf-idf features\n",
    "- Raw review length\n",
    "- Lix number [see here](https://en.wikipedia.org/wiki/Lix_(readability_test))\n",
    "- Sentiment score (3 scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/NLP_data.csv\")\n",
    "df['reviewTextClean'] = df['reviewTextClean'].str.lower()\n",
    "df.dropna(subset=[\"reviewTextClean\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTextClean</th>\n",
       "      <th>posReviewPercent</th>\n",
       "      <th>negReviewPercent</th>\n",
       "      <th>midReviewPercent</th>\n",
       "      <th>price</th>\n",
       "      <th>LIX</th>\n",
       "      <th>NumberOfWords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>This is a very cute hotel with good amenities ...</td>\n",
       "      <td>cute hotel good amenity nice location great cr...</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.751</td>\n",
       "      <td>3.0</td>\n",
       "      <td>28.500000</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Love this place.   The Great/Good:  Massage an...</td>\n",
       "      <td>love place massage facial technician best loun...</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.716</td>\n",
       "      <td>3.0</td>\n",
       "      <td>82.047619</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>service is amazing, the line goes so fast.</td>\n",
       "      <td>service amazing line go fast</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.648</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Get the chicken green salad. Yum.</td>\n",
       "      <td>get chicken green salad yum</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.666667</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Never had a falafel bar before. Yum. +1 for su...</td>\n",
       "      <td>never falafel bar yum super crunchy sweet pota...</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.734</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.047619</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                                         reviewText  \\\n",
       "0     3.0  This is a very cute hotel with good amenities ...   \n",
       "1     4.0  Love this place.   The Great/Good:  Massage an...   \n",
       "2     5.0         service is amazing, the line goes so fast.   \n",
       "3     5.0                  Get the chicken green salad. Yum.   \n",
       "4     5.0  Never had a falafel bar before. Yum. +1 for su...   \n",
       "\n",
       "                                     reviewTextClean  posReviewPercent  \\\n",
       "0  cute hotel good amenity nice location great cr...             0.141   \n",
       "1  love place massage facial technician best loun...             0.234   \n",
       "2                       service amazing line go fast             0.352   \n",
       "3                        get chicken green salad yum             0.000   \n",
       "4  never falafel bar yum super crunchy sweet pota...             0.266   \n",
       "\n",
       "   negReviewPercent  midReviewPercent  price        LIX  NumberOfWords  \n",
       "0             0.109             0.751    3.0  28.500000             50  \n",
       "1             0.051             0.716    3.0  82.047619             63  \n",
       "2             0.000             0.648    2.0  33.000000              8  \n",
       "3             0.000             1.000    1.0  19.666667              6  \n",
       "4             0.000             0.734    1.0  26.047619             21  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96001, 33795)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "bow_counts = count_vect.fit_transform(df['reviewTextClean'].values)\n",
    "bow_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary: 33795\n",
      "Length of corpus: 96001\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of vocabulary:\", len(count_vect.vocabulary_))\n",
    "print(\"Length of corpus:\", bow_counts.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create tf-idf representation of `reviewTextClean`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf = TfidfTransformer()\n",
    "bow_tfidf = tfidf.fit_transform(bow_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add remaining features to both bow_counts and bow_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rem_feats = csr_matrix(df[[\"posReviewPercent\", \"negReviewPercent\", \"midReviewPercent\", \"LIX\", \"NumberOfWords\"]])\n",
    "rem_feats = csr_matrix(df[[\"posReviewPercent\", \"negReviewPercent\", \"LIX\", \"NumberOfWords\"]])\n",
    "bow_counts_full = hstack([bow_counts, rem_feats]).tocsr()\n",
    "bow_tfidf_full = hstack([bow_tfidf, rem_feats]).tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the data is split into training and test. In this case, to keep a completely clean test set, two splits are made. First we split the data into a developement set and a test set. This test set is set aside for final testing once the models has been tuned. The developement set is then split into train and validation such that one can train and test a model as usual. This is done for both the bag of words set and the TF-IDF set in order to test the hypothesis that a TF-IDF performs better than a simple bag of words count. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = df.price.values-1\n",
    "\n",
    "# Split into development and test split for bow and tfidf only\n",
    "X_bow_dev, X_bow_test, X_tfidf_dev, X_tfidf_test, y_dev, y_test = train_test_split(bow_counts, bow_tfidf, y, test_size=0.2, stratify=y)\n",
    "\n",
    "# Split development into training and validation for bow and tfidf only\n",
    "X_bow_train, X_bow_val, X_tfidf_train, X_tfidf_val, y_train, y_val = train_test_split(X_bow_dev, X_tfidf_dev, y_dev, test_size=0.1, stratify=y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into development and test split for bow and tfidf as well as the other features\n",
    "X_bow_f_dev, X_bow_f_test, X_tfidf_f_dev, X_tfidf_f_test, y_f_dev, y_f_test = train_test_split(bow_counts_full, bow_tfidf_full, y, test_size=0.2, stratify=y)\n",
    "\n",
    "# Split development into training and validation for bow and tfidf as well as the other features\n",
    "X_bow_f_train, X_bow_f_val, X_tfidf_f_train, X_tfidf_f_val, y_f_train, y_f_val = train_test_split(X_bow_f_dev, X_tfidf_f_dev, y_dev, test_size=0.1, stratify=y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that returns performance of classifier \n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "def classification_metrics(header_text, clf, X_train, X_test, y_train, y_test):\n",
    "    print(\"=\"*35)\n",
    "    print(\" \"*int((35-len(header_text))/2), header_text)\n",
    "    print(\"=\"*35)\n",
    "    y_pred = clf.predict(X_train)\n",
    "    print(\"Train Accuracy:\", accuracy_score(y_train, y_pred))\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"Val Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"F1 Score:\", f1_score(y_test, y_pred, average=\"weighted\"))\n",
    "    print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First a simple dummy classifier was tested using the bag of word counts. It predicts the class of the observation from the most frequent class in the set. This performs about as well as expected with a accuracy of 55.82% for both training and validation. This is also the case when adding the additional features as the most frequent class in the observed y does not change with additional features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================\n",
      "          Dummy classifier\n",
      "===================================\n",
      "Train Accuracy: 0.5582465277777777\n",
      "Val Accuracy: 0.558203125\n",
      "F1 Score: 0.3999359566934069\n",
      "[[   0 1382    0]\n",
      " [   0 4287    0]\n",
      " [   0 2011    0]]\n"
     ]
    }
   ],
   "source": [
    "# Dummy classifier predicting most frequent class\n",
    "from sklearn.dummy import DummyClassifier\n",
    "dummy = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy.fit(X_bow_train, y_train)\n",
    "y_pred = dummy.predict(X_bow_val)\n",
    "classification_metrics(\"Dummy classifier\", dummy, X_bow_train, X_bow_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================\n",
      "          Dummy classifier\n",
      "===================================\n",
      "Train Accuracy: 0.5582465277777777\n",
      "Val Accuracy: 0.558203125\n",
      "F1 Score: 0.3999359566934069\n",
      "[[   0 1382    0]\n",
      " [   0 4287    0]\n",
      " [   0 2011    0]]\n"
     ]
    }
   ],
   "source": [
    "# Dummy classifier predicting most frequent class w/ all features\n",
    "dummy.fit(X_bow_f_train, y_f_train)\n",
    "y_pred = dummy.predict(X_bow_f_val)\n",
    "classification_metrics(\"Dummy classifier\", dummy, X_bow_f_train, X_bow_f_val, y_f_train, y_f_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the dummy classifier, the next step to test was the TF-IDF data. This was done using a logistic regression as that provides a discrete outcome. This performs significantly better than the dummy classifier with an accuracy of 65% on the validation set. When adding the extra features troubles arise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================\n",
      "      LogisticRegression tf-idf\n",
      "===================================\n",
      "Train Accuracy: 0.7212962962962963\n",
      "Val Accuracy: 0.6486979166666667\n",
      "F1 Score: 0.6280045725482722\n",
      "[[ 481  852   49]\n",
      " [ 230 3621  436]\n",
      " [  32 1099  880]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(solver=\"saga\")\n",
    "lr.fit(X_tfidf_train, y_train)\n",
    "classification_metrics(\"LogisticRegression tf-idf\", lr, X_tfidf_train, X_tfidf_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================\n",
      "      LogisticRegression tf-idf\n",
      "===================================\n",
      "Train Accuracy: 0.5582465277777777\n",
      "Val Accuracy: 0.558203125\n",
      "F1 Score: 0.3999359566934069\n",
      "[[   0 1382    0]\n",
      " [   0 4287    0]\n",
      " [   0 2011    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(solver=\"saga\", max_iter=2000)\n",
    "lr.fit(X_tfidf_f_train, y_f_train)\n",
    "classification_metrics(\"LogisticRegression tf-idf\", lr, X_tfidf_f_train, X_tfidf_f_val, y_f_train, y_f_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, xgboost is employed to see what a Gradient Boosting can do to classify the price points of the establishments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================\n",
      "           XGBoost tf-idf\n",
      "===================================\n",
      "Train Accuracy: 0.5932002314814815\n",
      "Val Accuracy: 0.5876302083333333\n",
      "F1 Score: 0.4814103155596096\n",
      "[[ 144 1231    7]\n",
      " [  36 4182   69]\n",
      " [   2 1822  187]]\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "xgb = xgboost.XGBClassifier(eval_metric=\"mlogloss\", use_label_encoder=False)\n",
    "xgb.fit(X_tfidf_train, y_train)\n",
    "classification_metrics(\"XGBoost tf-idf\", xgb, X_tfidf_train, X_tfidf_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================\n",
      "           XGBoost tf-idf\n",
      "===================================\n",
      "Train Accuracy: 0.5586805555555555\n",
      "Val Accuracy: 0.5579427083333334\n",
      "F1 Score: 0.399816195674885\n",
      "[[   0 1382    0]\n",
      " [   0 4285    2]\n",
      " [   0 2011    0]]\n"
     ]
    }
   ],
   "source": [
    "xgb.fit(X_tfidf_f_train, y_f_train)\n",
    "classification_metrics(\"XGBoost tf-idf\", xgb, X_tfidf_f_train, X_tfidf_f_val, y_f_train, y_f_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6f9910882fae098898ae321f07726ec847ec186b3979568b9e6c54444f9aa773"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
