{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Grid</th>\n",
       "      <th>PlaceCount</th>\n",
       "      <th>Price 1</th>\n",
       "      <th>Price 2</th>\n",
       "      <th>Price 3</th>\n",
       "      <th>Accommodation</th>\n",
       "      <th>Bar</th>\n",
       "      <th>Cafe</th>\n",
       "      <th>Cultural</th>\n",
       "      <th>Education</th>\n",
       "      <th>...</th>\n",
       "      <th>Health_rating</th>\n",
       "      <th>Other_rating</th>\n",
       "      <th>Outdoors_rating</th>\n",
       "      <th>Restaurant_rating</th>\n",
       "      <th>Retail_rating</th>\n",
       "      <th>Service_rating</th>\n",
       "      <th>Wholesale_rating</th>\n",
       "      <th>PositiveReviews</th>\n",
       "      <th>NegativeReviews</th>\n",
       "      <th>ReviewLength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.020000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.942857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.696000</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.536595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.777778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.802238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.999095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L100</td>\n",
       "      <td>74</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.024460</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.711172</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>3.028846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.732975</td>\n",
       "      <td>0.267025</td>\n",
       "      <td>0.895548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L101</td>\n",
       "      <td>163</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>21.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.223132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.748855</td>\n",
       "      <td>3.549446</td>\n",
       "      <td>4.311111</td>\n",
       "      <td>3.722222</td>\n",
       "      <td>0.801535</td>\n",
       "      <td>0.198465</td>\n",
       "      <td>0.843739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Grid  PlaceCount  Price 1  Price 2  Price 3  Accommodation   Bar  Cafe  \\\n",
       "0    L0           8        0        1        0            0.0   0.0   0.0   \n",
       "1    L1          10        0        1        0            0.0   0.0   1.0   \n",
       "2   L10           3        0        0        0            0.0   0.0   0.0   \n",
       "3  L100          74        2        9        6           12.0   6.0   6.0   \n",
       "4  L101         163        7       31        5           21.0  19.0  20.0   \n",
       "\n",
       "   Cultural  Education  ...  Health_rating  Other_rating  Outdoors_rating  \\\n",
       "0       0.0        0.0  ...            0.0      4.020000              0.0   \n",
       "1       0.0        0.0  ...            5.0      0.000000              0.0   \n",
       "2       0.0        1.0  ...            0.0      4.200000              0.0   \n",
       "3       0.0        1.0  ...            3.6      4.024460              0.0   \n",
       "4       1.0        1.0  ...            4.5      4.223132              0.0   \n",
       "\n",
       "   Restaurant_rating  Retail_rating  Service_rating  Wholesale_rating  \\\n",
       "0           3.942857       0.000000        0.000000          0.000000   \n",
       "1           4.777778       0.000000        4.000000          0.000000   \n",
       "2           0.000000       0.000000        0.000000          0.000000   \n",
       "3           3.711172       4.500000        3.028846          0.000000   \n",
       "4           3.748855       3.549446        4.311111          3.722222   \n",
       "\n",
       "   PositiveReviews  NegativeReviews  ReviewLength  \n",
       "0         0.696000         0.304000      0.536595  \n",
       "1         0.851852         0.148148      0.802238  \n",
       "2         0.857143         0.142857      0.999095  \n",
       "3         0.732975         0.267025      0.895548  \n",
       "4         0.801535         0.198465      0.843739  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"data/space_embedding_data.csv\", index_col=[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.fillna(2, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[[i for i in df.columns if \"_rating\" not in i]].drop([\"Grid\"], axis=1)\n",
    "X = pd.get_dummies(df.Grid).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "y_tf = sc.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import Input\n",
    "# Parameters\n",
    "input_neurons = X.shape[0] #df.Grid.nunique()\n",
    "output_neurons = y.shape[1] #df.shape[-1]-1\n",
    "act_f = 'relu'\n",
    "hidden_neurons = 2056\n",
    "\n",
    "# Model architecture\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(input_neurons,)))\n",
    "model.add(Dense(hidden_neurons, activation=act_f))\n",
    "model.add(Dense(output_neurons, activation=act_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 1.0021 - mean_squared_error: 1.0021\n",
      "Epoch 2/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.9990 - mean_squared_error: 0.9990\n",
      "Epoch 3/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.9864 - mean_squared_error: 0.9864\n",
      "Epoch 4/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.9514 - mean_squared_error: 0.9514\n",
      "Epoch 5/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.8609 - mean_squared_error: 0.8609\n",
      "Epoch 6/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.7425 - mean_squared_error: 0.7425\n",
      "Epoch 7/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6797 - mean_squared_error: 0.6797\n",
      "Epoch 8/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.6393 - mean_squared_error: 0.6393\n",
      "Epoch 9/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5932 - mean_squared_error: 0.5932\n",
      "Epoch 10/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5625 - mean_squared_error: 0.5625\n",
      "Epoch 11/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5595 - mean_squared_error: 0.5595\n",
      "Epoch 12/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5519 - mean_squared_error: 0.5519\n",
      "Epoch 13/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5393 - mean_squared_error: 0.5393\n",
      "Epoch 14/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5248 - mean_squared_error: 0.5248\n",
      "Epoch 15/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5185 - mean_squared_error: 0.5185\n",
      "Epoch 16/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5107 - mean_squared_error: 0.5107\n",
      "Epoch 17/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5125 - mean_squared_error: 0.5125\n",
      "Epoch 18/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5141 - mean_squared_error: 0.5141\n",
      "Epoch 19/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5205 - mean_squared_error: 0.5205\n",
      "Epoch 20/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5101 - mean_squared_error: 0.5101\n",
      "Epoch 21/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5077 - mean_squared_error: 0.5077\n",
      "Epoch 22/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5045 - mean_squared_error: 0.5045\n",
      "Epoch 23/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5035 - mean_squared_error: 0.5035\n",
      "Epoch 24/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4999 - mean_squared_error: 0.4999\n",
      "Epoch 25/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5014 - mean_squared_error: 0.5014\n",
      "Epoch 26/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5002 - mean_squared_error: 0.5002\n",
      "Epoch 27/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4991 - mean_squared_error: 0.4991\n",
      "Epoch 28/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4977 - mean_squared_error: 0.4977\n",
      "Epoch 29/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4974 - mean_squared_error: 0.4974\n",
      "Epoch 30/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4930 - mean_squared_error: 0.4930\n",
      "Epoch 31/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4925 - mean_squared_error: 0.4925\n",
      "Epoch 32/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4921 - mean_squared_error: 0.4921\n",
      "Epoch 33/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4816 - mean_squared_error: 0.4816\n",
      "Epoch 34/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4601 - mean_squared_error: 0.4601\n",
      "Epoch 35/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4583 - mean_squared_error: 0.4583\n",
      "Epoch 36/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4570 - mean_squared_error: 0.4570\n",
      "Epoch 37/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4536 - mean_squared_error: 0.4536\n",
      "Epoch 38/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4559 - mean_squared_error: 0.4559\n",
      "Epoch 39/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4565 - mean_squared_error: 0.4565\n",
      "Epoch 40/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4523 - mean_squared_error: 0.4523\n",
      "Epoch 41/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4504 - mean_squared_error: 0.4504\n",
      "Epoch 42/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4478 - mean_squared_error: 0.4478\n",
      "Epoch 43/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4477 - mean_squared_error: 0.4477\n",
      "Epoch 44/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4450 - mean_squared_error: 0.4450\n",
      "Epoch 45/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4465 - mean_squared_error: 0.4465\n",
      "Epoch 46/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4490 - mean_squared_error: 0.4490\n",
      "Epoch 47/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4535 - mean_squared_error: 0.4535\n",
      "Epoch 48/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4510 - mean_squared_error: 0.4510\n",
      "Epoch 49/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4519 - mean_squared_error: 0.4519\n",
      "Epoch 50/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4520 - mean_squared_error: 0.4520\n",
      "Epoch 51/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4488 - mean_squared_error: 0.4488\n",
      "Epoch 52/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4470 - mean_squared_error: 0.4470\n",
      "Epoch 53/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4462 - mean_squared_error: 0.4462\n",
      "Epoch 54/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4474 - mean_squared_error: 0.4474\n",
      "Epoch 55/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4471 - mean_squared_error: 0.4471\n",
      "Epoch 56/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4443 - mean_squared_error: 0.4443\n",
      "Epoch 57/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4435 - mean_squared_error: 0.4435\n",
      "Epoch 58/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4404 - mean_squared_error: 0.4404\n",
      "Epoch 59/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4386 - mean_squared_error: 0.4386\n",
      "Epoch 60/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4379 - mean_squared_error: 0.4379\n",
      "Epoch 61/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4377 - mean_squared_error: 0.4377\n",
      "Epoch 62/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4386 - mean_squared_error: 0.4386\n",
      "Epoch 63/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4399 - mean_squared_error: 0.4399\n",
      "Epoch 64/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4406 - mean_squared_error: 0.4406\n",
      "Epoch 65/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4384 - mean_squared_error: 0.4384\n",
      "Epoch 66/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4394 - mean_squared_error: 0.4394\n",
      "Epoch 67/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4414 - mean_squared_error: 0.4414\n",
      "Epoch 68/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4398 - mean_squared_error: 0.4398\n",
      "Epoch 69/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4411 - mean_squared_error: 0.4411\n",
      "Epoch 70/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4417 - mean_squared_error: 0.4417\n",
      "Epoch 71/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4434 - mean_squared_error: 0.4434\n",
      "Epoch 72/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4471 - mean_squared_error: 0.4471\n",
      "Epoch 73/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4402 - mean_squared_error: 0.4402\n",
      "Epoch 74/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4381 - mean_squared_error: 0.4381\n",
      "Epoch 75/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4387 - mean_squared_error: 0.4387\n",
      "Epoch 76/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4380 - mean_squared_error: 0.4380\n",
      "Epoch 77/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4377 - mean_squared_error: 0.4377\n",
      "Epoch 78/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4376 - mean_squared_error: 0.4376\n",
      "Epoch 79/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4382 - mean_squared_error: 0.4382\n",
      "Epoch 80/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4376 - mean_squared_error: 0.4376\n",
      "Epoch 81/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4394 - mean_squared_error: 0.4394\n",
      "Epoch 82/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4396 - mean_squared_error: 0.4396\n",
      "Epoch 83/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4409 - mean_squared_error: 0.4409\n",
      "Epoch 84/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4437 - mean_squared_error: 0.4437\n",
      "Epoch 85/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4438 - mean_squared_error: 0.4438\n",
      "Epoch 86/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4427 - mean_squared_error: 0.4427\n",
      "Epoch 87/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4423 - mean_squared_error: 0.4423\n",
      "Epoch 88/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4494 - mean_squared_error: 0.4494\n",
      "Epoch 89/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4507 - mean_squared_error: 0.4507\n",
      "Epoch 90/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4458 - mean_squared_error: 0.4458\n",
      "Epoch 91/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4450 - mean_squared_error: 0.4450\n",
      "Epoch 92/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4429 - mean_squared_error: 0.4429\n",
      "Epoch 93/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4450 - mean_squared_error: 0.4450\n",
      "Epoch 94/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4463 - mean_squared_error: 0.4463\n",
      "Epoch 95/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4414 - mean_squared_error: 0.4414\n",
      "Epoch 96/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4377 - mean_squared_error: 0.4377\n",
      "Epoch 97/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4359 - mean_squared_error: 0.4359\n",
      "Epoch 98/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4356 - mean_squared_error: 0.4356\n",
      "Epoch 99/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4346 - mean_squared_error: 0.4346\n",
      "Epoch 100/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4348 - mean_squared_error: 0.4348\n",
      "Epoch 101/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4369 - mean_squared_error: 0.4369\n",
      "Epoch 102/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4355 - mean_squared_error: 0.4355\n",
      "Epoch 103/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4375 - mean_squared_error: 0.4375\n",
      "Epoch 104/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4350 - mean_squared_error: 0.4350\n",
      "Epoch 105/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4352 - mean_squared_error: 0.4352\n",
      "Epoch 106/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4329 - mean_squared_error: 0.4329\n",
      "Epoch 107/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4340 - mean_squared_error: 0.4340\n",
      "Epoch 108/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4333 - mean_squared_error: 0.4333\n",
      "Epoch 109/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4345 - mean_squared_error: 0.4345\n",
      "Epoch 110/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4363 - mean_squared_error: 0.4363\n",
      "Epoch 111/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4352 - mean_squared_error: 0.4352\n",
      "Epoch 112/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4347 - mean_squared_error: 0.4347\n",
      "Epoch 113/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4356 - mean_squared_error: 0.4356\n",
      "Epoch 114/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4354 - mean_squared_error: 0.4354\n",
      "Epoch 115/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4383 - mean_squared_error: 0.4383\n",
      "Epoch 116/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4390 - mean_squared_error: 0.4390\n",
      "Epoch 117/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4394 - mean_squared_error: 0.4394\n",
      "Epoch 118/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4345 - mean_squared_error: 0.4345\n",
      "Epoch 119/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4332 - mean_squared_error: 0.4332\n",
      "Epoch 120/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4324 - mean_squared_error: 0.4324\n",
      "Epoch 121/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4317 - mean_squared_error: 0.4317\n",
      "Epoch 122/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4320 - mean_squared_error: 0.4320\n",
      "Epoch 123/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4312 - mean_squared_error: 0.4312\n",
      "Epoch 124/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4313 - mean_squared_error: 0.4313\n",
      "Epoch 125/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4305 - mean_squared_error: 0.4305\n",
      "Epoch 126/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4301 - mean_squared_error: 0.4301\n",
      "Epoch 127/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4300 - mean_squared_error: 0.4300\n",
      "Epoch 128/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4306 - mean_squared_error: 0.4306\n",
      "Epoch 129/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4312 - mean_squared_error: 0.4312\n",
      "Epoch 130/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4320 - mean_squared_error: 0.4320\n",
      "Epoch 131/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4342 - mean_squared_error: 0.4342\n",
      "Epoch 132/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4351 - mean_squared_error: 0.4351\n",
      "Epoch 133/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4357 - mean_squared_error: 0.4357\n",
      "Epoch 134/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4336 - mean_squared_error: 0.4336\n",
      "Epoch 135/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4327 - mean_squared_error: 0.4327\n",
      "Epoch 136/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4316 - mean_squared_error: 0.4316\n",
      "Epoch 137/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4322 - mean_squared_error: 0.4322\n",
      "Epoch 138/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4338 - mean_squared_error: 0.4338\n",
      "Epoch 139/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4355 - mean_squared_error: 0.4355\n",
      "Epoch 140/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4361 - mean_squared_error: 0.4361\n",
      "Epoch 141/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4349 - mean_squared_error: 0.4349\n",
      "Epoch 142/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4333 - mean_squared_error: 0.4333\n",
      "Epoch 143/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4331 - mean_squared_error: 0.4331\n",
      "Epoch 144/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4330 - mean_squared_error: 0.4330\n",
      "Epoch 145/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4325 - mean_squared_error: 0.4325\n",
      "Epoch 146/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4339 - mean_squared_error: 0.4339\n",
      "Epoch 147/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4367 - mean_squared_error: 0.4367\n",
      "Epoch 148/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4340 - mean_squared_error: 0.4340\n",
      "Epoch 149/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4354 - mean_squared_error: 0.4354\n",
      "Epoch 150/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4355 - mean_squared_error: 0.4355\n",
      "Epoch 151/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4332 - mean_squared_error: 0.4332\n",
      "Epoch 152/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4335 - mean_squared_error: 0.4335\n",
      "Epoch 153/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4339 - mean_squared_error: 0.4339\n",
      "Epoch 154/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4330 - mean_squared_error: 0.4330\n",
      "Epoch 155/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4332 - mean_squared_error: 0.4332\n",
      "Epoch 156/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4338 - mean_squared_error: 0.4338\n",
      "Epoch 157/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4330 - mean_squared_error: 0.4330\n",
      "Epoch 158/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4332 - mean_squared_error: 0.4332\n",
      "Epoch 159/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4350 - mean_squared_error: 0.4350\n",
      "Epoch 160/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4355 - mean_squared_error: 0.4355\n",
      "Epoch 161/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4359 - mean_squared_error: 0.4359\n",
      "Epoch 162/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4340 - mean_squared_error: 0.4340\n",
      "Epoch 163/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4328 - mean_squared_error: 0.4328\n",
      "Epoch 164/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4322 - mean_squared_error: 0.4322\n",
      "Epoch 165/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4305 - mean_squared_error: 0.4305\n",
      "Epoch 166/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4248 - mean_squared_error: 0.4248\n",
      "Epoch 167/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4250 - mean_squared_error: 0.4250\n",
      "Epoch 168/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4242 - mean_squared_error: 0.4242\n",
      "Epoch 169/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4236 - mean_squared_error: 0.4236\n",
      "Epoch 170/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4239 - mean_squared_error: 0.4239\n",
      "Epoch 171/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4227 - mean_squared_error: 0.4227\n",
      "Epoch 172/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4222 - mean_squared_error: 0.4222\n",
      "Epoch 173/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4214 - mean_squared_error: 0.4214\n",
      "Epoch 174/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4215 - mean_squared_error: 0.4215\n",
      "Epoch 175/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4206 - mean_squared_error: 0.4206\n",
      "Epoch 176/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4204 - mean_squared_error: 0.4204\n",
      "Epoch 177/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4206 - mean_squared_error: 0.4206\n",
      "Epoch 178/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4221 - mean_squared_error: 0.4221\n",
      "Epoch 179/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4273 - mean_squared_error: 0.4273\n",
      "Epoch 180/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4280 - mean_squared_error: 0.4280\n",
      "Epoch 181/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4253 - mean_squared_error: 0.4253\n",
      "Epoch 182/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4237 - mean_squared_error: 0.4237\n",
      "Epoch 183/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4220 - mean_squared_error: 0.4220\n",
      "Epoch 184/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4206 - mean_squared_error: 0.4206\n",
      "Epoch 185/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4201 - mean_squared_error: 0.4201\n",
      "Epoch 186/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4209 - mean_squared_error: 0.4209\n",
      "Epoch 187/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4208 - mean_squared_error: 0.4208\n",
      "Epoch 188/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4204 - mean_squared_error: 0.4204\n",
      "Epoch 189/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4195 - mean_squared_error: 0.4195\n",
      "Epoch 190/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4195 - mean_squared_error: 0.4195\n",
      "Epoch 191/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4195 - mean_squared_error: 0.4195\n",
      "Epoch 192/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4204 - mean_squared_error: 0.4204\n",
      "Epoch 193/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4205 - mean_squared_error: 0.4205\n",
      "Epoch 194/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4200 - mean_squared_error: 0.4200\n",
      "Epoch 195/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4213 - mean_squared_error: 0.4213\n",
      "Epoch 196/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4223 - mean_squared_error: 0.4223\n",
      "Epoch 197/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4221 - mean_squared_error: 0.4221\n",
      "Epoch 198/200\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.4231 - mean_squared_error: 0.4231\n",
      "Epoch 199/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4213 - mean_squared_error: 0.4213\n",
      "Epoch 200/200\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4214 - mean_squared_error: 0.4214\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "opt = Adam(learning_rate=0.01)\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=opt, metrics=[\"mean_squared_error\"])\n",
    "\n",
    "batch_size = 12\n",
    "epochs = 200\n",
    "history = model.fit(X, y_tf, batch_size=batch_size, epochs=epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.epoch, history.history['loss'])\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4208329530484039"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "y_pred = model.predict(X)\n",
    "mean_squared_error(y_tf, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.01134083, -0.16404057,  0.00952493, ..., -0.00053272,\n",
       "         -0.03091468, -0.03499408],\n",
       "        [-0.09525383,  0.02668817, -0.02657523, ...,  0.04131517,\n",
       "         -0.02131649,  0.00855051],\n",
       "        [ 0.00296148,  0.03045608,  0.01837367, ...,  0.03655125,\n",
       "         -0.04142128, -0.04060674],\n",
       "        ...,\n",
       "        [-0.02834114, -0.03939577,  0.08375563, ...,  0.02889028,\n",
       "          0.09156764, -0.01894287],\n",
       "        [-0.24081452, -0.01410685, -0.03065039, ...,  0.03769118,\n",
       "          0.04362059, -0.01870783],\n",
       "        [ 0.00561729, -0.20646785, -0.02653866, ..., -0.04685046,\n",
       "          0.00934385, -0.03021444]], dtype=float32),\n",
       " array([-0.45894912, -0.55783904, -0.43361044, ..., -0.11465064,\n",
       "        -0.30060208, -0.28168747], dtype=float32)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.analyticsvidhya.com/blog/2021/05/tuning-the-hyperparameters-and-layers-of-neural-network-deep-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import KFold\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function\n",
    "# https://www.analyticsvidhya.com/blog/2021/05/tuning-the-hyperparameters-and-layers-of-neural-network-deep-learning/\n",
    "def optimize(neurons, activation, learning_rate,  batch_size, epochs):\n",
    "\n",
    "    activationL = ['relu', 'sigmoid', 'tanh', 'exponential']\n",
    "\n",
    "    neurons = round(neurons)\n",
    "    activation = activationL[round(activation)]\n",
    "    batch_size = round(batch_size)\n",
    "    epochs = round(epochs)\n",
    "    \n",
    "\n",
    "    def build_nn():\n",
    "        nn = Sequential()\n",
    "        nn.add(Input(shape=(input_neurons,)))\n",
    "        nn.add(Dense(hidden_neurons, activation=activation))\n",
    "        nn.add(Dense(output_neurons, activation='relu'))\n",
    "\n",
    "        opt = Adam(lr = learning_rate)\n",
    "        nn.compile(loss=\"mean_squared_error\", optimizer=opt, metrics=[\"mean_squared_error\"])\n",
    "        \n",
    "        return nn\n",
    "\n",
    "\n",
    "    es = EarlyStopping(monitor='mean_squared_error', mode='min', verbose=False, patience=20)\n",
    "\n",
    "    nn = KerasRegressor(build_fn=build_nn, epochs=epochs, batch_size=batch_size,\n",
    "                         verbose=False)\n",
    "\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=123)\n",
    "\n",
    "    score = cross_val_score(nn, X, y_tf, scoring='neg_mean_squared_error', cv=kfold, fit_params={'callbacks':[es]}).mean()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | activa... | batch_... |  epochs   | learni... |  neurons  |\n",
      "-------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m 2.089   \u001b[0m | \u001b[0m 6.437   \u001b[0m | \u001b[0m 145.4   \u001b[0m | \u001b[0m 0.5558  \u001b[0m | \u001b[0m 887.8   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m 1.269   \u001b[0m | \u001b[0m 19.63   \u001b[0m | \u001b[0m 237.0   \u001b[0m | \u001b[0m 0.4861  \u001b[0m | \u001b[0m 756.8   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m 1.03    \u001b[0m | \u001b[0m 14.85   \u001b[0m | \u001b[0m 187.7   \u001b[0m | \u001b[0m 0.06908 \u001b[0m | \u001b[0m 759.2   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m 2.214   \u001b[0m | \u001b[0m 4.467   \u001b[0m | \u001b[0m 135.1   \u001b[0m | \u001b[0m 0.5362  \u001b[0m | \u001b[0m 812.7   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m 1.903   \u001b[0m | \u001b[0m 17.14   \u001b[0m | \u001b[0m 244.9   \u001b[0m | \u001b[0m 0.6149  \u001b[0m | \u001b[0m 889.0   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m 2.44    \u001b[0m | \u001b[0m 4.719   \u001b[0m | \u001b[0m 104.6   \u001b[0m | \u001b[0m 0.7045  \u001b[0m | \u001b[0m 601.1   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-1.0     \u001b[0m | \u001b[0m 2.344   \u001b[0m | \u001b[0m 14.06   \u001b[0m | \u001b[0m 296.0   \u001b[0m | \u001b[0m 0.2775  \u001b[0m | \u001b[0m 603.4   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m nan     \u001b[0m | \u001b[0m 2.638   \u001b[0m | \u001b[0m 3.555   \u001b[0m | \u001b[0m 297.8   \u001b[0m | \u001b[0m 0.7587  \u001b[0m | \u001b[0m 999.8   \u001b[0m |\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, init_points, n_iter, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                 \u001b[0mx_probe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Queue is empty, no more objects to retrieve.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: Queue is empty, no more objects to retrieve.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/k9/6q_wnl392rn1_6g2d_l2hnrh0000gr/T/ipykernel_16627/1500747739.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Run Bayesian Optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mnn_bo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBayesianOptimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_nn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m123\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mnn_bo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, init_points, n_iter, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m                 \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m                 \u001b[0mx_probe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36msuggest\u001b[0;34m(self, utility_function)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# Finding argmax of the acquisition function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/gaussian_process/_gpr.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_vector_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m             X, y = self._validate_data(X, y, multi_output=True, y_numeric=True,\n\u001b[0m\u001b[1;32m    194\u001b[0m                                        ensure_2d=True, dtype=\"numeric\")\n\u001b[1;32m    195\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    878\u001b[0m                     estimator=estimator)\n\u001b[1;32m    879\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         y = check_array(y, accept_sparse='csr', force_all_finite=True,\n\u001b[0m\u001b[1;32m    881\u001b[0m                         ensure_2d=False, dtype=None)\n\u001b[1;32m    882\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m             _assert_all_finite(array,\n\u001b[0m\u001b[1;32m    721\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m    102\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    104\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                     (type_err,\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "params_nn ={\n",
    "    'neurons': (600, 1000),\n",
    "    'activation':(0, 3),\n",
    "    'learning_rate':(0.01, 1),\n",
    "    'batch_size':(1, 20),\n",
    "    'epochs':(100, 300)\n",
    "}\n",
    "\n",
    "# Run Bayesian Optimization\n",
    "nn_bo = BayesianOptimization(optimize, params_nn, random_state=123)\n",
    "nn_bo.maximize(init_points=5, n_iter=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions for Ioanna\n",
    "- Can we use the weights from the hidden layer to the output layer?\n",
    "- How to determine amount of neurons in hidden layer?\n",
    "    - How to perform cross validation? Evaluate score on full set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['explained_variance', 'r2', 'max_error', 'neg_median_absolute_error', 'neg_mean_absolute_error', 'neg_mean_absolute_percentage_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'neg_root_mean_squared_error', 'neg_mean_poisson_deviance', 'neg_mean_gamma_deviance', 'accuracy', 'top_k_accuracy', 'roc_auc', 'roc_auc_ovr', 'roc_auc_ovo', 'roc_auc_ovr_weighted', 'roc_auc_ovo_weighted', 'balanced_accuracy', 'average_precision', 'neg_log_loss', 'neg_brier_score', 'adjusted_rand_score', 'rand_score', 'homogeneity_score', 'completeness_score', 'v_measure_score', 'mutual_info_score', 'adjusted_mutual_info_score', 'normalized_mutual_info_score', 'fowlkes_mallows_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'jaccard', 'jaccard_macro', 'jaccard_micro', 'jaccard_samples', 'jaccard_weighted'])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.metrics.SCORERS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6f9910882fae098898ae321f07726ec847ec186b3979568b9e6c54444f9aa773"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('abaenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
