{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.sparse import hstack, vstack, coo_matrix, csr_matrix, bmat\n",
    "sns.set_style(\"darkgrid\")\n",
    "data_path = \"data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to give better reccomendations to travellers, the price point of a shop or restaurant is essential. A student, living of a part time job has a different budget than the business traveler. Thus, if you often visit cheap eats you'll likely love the areas at your destination that serve streetfood and the like, while the guy putting down the company card will have no qualms about having an expensive meal. \n",
    "\n",
    "In this section a model to predict prices will be built. The model will be based on the following features:\n",
    "- Bag of Words or TF-IDF features\n",
    "- Raw review length\n",
    "- Lix number [see here](https://en.wikipedia.org/wiki/Lix_(readability_test))\n",
    "- Sentiment score (VADER)\n",
    "\n",
    "First of all, the reviews will be used to predict the price of the reviewed place. Either a bag of words count or a TF-IDF will be used, with the thesis that TF-IDF will perform better. The BoW count simply tells how any times a word is used in a review where TF-IDF show the relative importance of a given word in the review, taking into account all reviews.  \n",
    "\n",
    "Secondly the length of the review is thought to influence the price in some way. It can be argued that it could affect both negatively and positively as long reviews tend to be either very positive or negative.\n",
    "\n",
    "The LIX number is an index that indicates readability of a text. It provides a number from zero and up (though likely below 100), which indicates how hard the text is to understand. It follows that below 25 are kids books and 35 to 45 is around the level of most newspapers. Above 55 is usually reserved for hard academic papers. The thesis is that more eloquent reviews might lead to a higher price. \n",
    "\n",
    "Finally, the sentiment score is calculated using the VADER (Valence Aware Dictionary and sEntiment Reasoner) framework. This is a popular and powerful framework for performing sentiment analysis and provides three values for a given text. The degree to which the text is positive, negative and neutral. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the preprocessed NLP data is loaded and prepared for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/NLP_data.csv\")\n",
    "df['reviewTextClean'] = df['reviewTextClean'].str.lower()\n",
    "df.dropna(subset=[\"reviewTextClean\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTextClean</th>\n",
       "      <th>posReviewPercent</th>\n",
       "      <th>negReviewPercent</th>\n",
       "      <th>midReviewPercent</th>\n",
       "      <th>price</th>\n",
       "      <th>LIX</th>\n",
       "      <th>NumberOfWords</th>\n",
       "      <th>gPlusPlaceId</th>\n",
       "      <th>LIXNorm</th>\n",
       "      <th>NoWNorm</th>\n",
       "      <th>pred_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>This is a very cute hotel with good amenities ...</td>\n",
       "      <td>cute hotel good amenity nice location great cr...</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.751</td>\n",
       "      <td>3</td>\n",
       "      <td>28.500000</td>\n",
       "      <td>50</td>\n",
       "      <td>106689630448064755324</td>\n",
       "      <td>0.122060</td>\n",
       "      <td>0.064644</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Love this place.   The Great/Good:  Massage an...</td>\n",
       "      <td>love place massage facial technician best loun...</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.716</td>\n",
       "      <td>3</td>\n",
       "      <td>82.047619</td>\n",
       "      <td>63</td>\n",
       "      <td>108256990636148259283</td>\n",
       "      <td>0.352293</td>\n",
       "      <td>0.081794</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>service is amazing, the line goes so fast.</td>\n",
       "      <td>service amazing line go fast</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.648</td>\n",
       "      <td>2</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>105947477166033397439</td>\n",
       "      <td>0.141409</td>\n",
       "      <td>0.009235</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                                         reviewText  \\\n",
       "0     3.0  This is a very cute hotel with good amenities ...   \n",
       "1     4.0  Love this place.   The Great/Good:  Massage an...   \n",
       "2     5.0         service is amazing, the line goes so fast.   \n",
       "\n",
       "                                     reviewTextClean  posReviewPercent  \\\n",
       "0  cute hotel good amenity nice location great cr...             0.141   \n",
       "1  love place massage facial technician best loun...             0.234   \n",
       "2                       service amazing line go fast             0.352   \n",
       "\n",
       "   negReviewPercent  midReviewPercent  price        LIX  NumberOfWords  \\\n",
       "0             0.109             0.751      3  28.500000             50   \n",
       "1             0.051             0.716      3  82.047619             63   \n",
       "2             0.000             0.648      2  33.000000              8   \n",
       "\n",
       "            gPlusPlaceId   LIXNorm   NoWNorm  pred_price  \n",
       "0  106689630448064755324  0.122060  0.064644           3  \n",
       "1  108256990636148259283  0.352293  0.081794           2  \n",
       "2  105947477166033397439  0.141409  0.009235           1  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96001, 33795)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "bow_counts = count_vect.fit_transform(df['reviewTextClean'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary: 33795\n",
      "Length of corpus: 96001\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of vocabulary:\", len(count_vect.vocabulary_))\n",
    "print(\"Length of corpus:\", bow_counts.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create tf-idf representation of `reviewTextClean`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf = TfidfTransformer()\n",
    "bow_tfidf = tfidf.fit_transform(bow_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add remaining features to both bow_counts and bow_tfidf. Here, both LIX and Number of Words are fitted such that they take values between zero and one to match the scale of the TF-IDF. This is done using min-max scaling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df[[\"LIXNorm\", \"NoWNorm\"]] = scaler.fit_transform(df[[\"LIX\", \"NumberOfWords\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"price\"] = df[\"price\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neutral sentiment score is not added as a feature. It would be heavily correlated with the positive and negative sentiment scores, since the three sum to one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rem_feats = csr_matrix(df[[\"posReviewPercent\", \"negReviewPercent\", \"LIXNorm\", \"NoWNorm\"]])\n",
    "bow_counts_full = hstack([bow_counts, rem_feats]).tocsr()\n",
    "bow_tfidf_full = hstack([bow_tfidf, rem_feats]).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<96001x33795 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2035355 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<96001x33799 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2350414 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_counts_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1254)\t0.2865966896963391\n",
      "  (0, 2533)\t0.10711259765276591\n",
      "  (0, 6048)\t0.27831494510811655\n",
      "  (0, 7158)\t0.28031377173992783\n",
      "  (0, 7583)\t0.16834943938545552\n",
      "  (0, 8103)\t0.2545201118484472\n",
      "  (0, 9298)\t0.10483606009852262\n",
      "  (0, 11508)\t0.1564140656440828\n",
      "  (0, 12864)\t0.06794621292653356\n",
      "  (0, 13111)\t0.0694752219899452\n",
      "  (0, 14447)\t0.3576194807022489\n",
      "  (0, 16802)\t0.14417594583527765\n",
      "  (0, 17415)\t0.1284114453908536\n",
      "  (0, 19909)\t0.13346342235554148\n",
      "  (0, 20051)\t0.09669954162366268\n",
      "  (0, 26347)\t0.16408146827974746\n",
      "  (0, 27946)\t0.2000790176860044\n",
      "  (0, 28372)\t0.09847745742261445\n",
      "  (0, 30105)\t0.12602822034467961\n",
      "  (0, 30254)\t0.2728413629251984\n",
      "  (0, 30982)\t0.16176057418419473\n",
      "  (0, 31186)\t0.25223180565723413\n",
      "  (0, 31797)\t0.25635987216511785\n",
      "  (0, 32542)\t0.15739559923055757\n",
      "  (0, 33301)\t0.2697086464659349\n",
      "  (0, 33795)\t0.141\n",
      "  (0, 33796)\t0.109\n",
      "  (0, 33797)\t0.1220604978234178\n",
      "  (0, 33798)\t0.06464379947229551\n"
     ]
    }
   ],
   "source": [
    "print(bow_tfidf_full[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the data is split into training and test. In this case, to keep a completely clean test set, two splits are made. First we split the data into a developement set and a test set. This test set is set aside for final testing once the models has been tuned. The developement set is then split into train and validation such that one can train and test a model as usual. This is done for both the bag of words set and the TF-IDF set in order to test the hypothesis that a TF-IDF performs better than a simple bag of words count. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = df.price.values-1\n",
    "\n",
    "# Split into development and test split for bow and tfidf only\n",
    "X_bow_dev, X_bow_test, X_tfidf_dev, X_tfidf_test, X_tfidf_f_dev, X_tfidf_f_test, y_dev, y_test = train_test_split(bow_counts, bow_tfidf, bow_tfidf_full, y, test_size=0.2, stratify=y)\n",
    "\n",
    "# Split development into training and validation for bow and tfidf only\n",
    "X_bow_train, X_bow_val, X_tfidf_train, X_tfidf_val, X_tfidf_f_train, X_tfidf_f_val, y_train, y_val = train_test_split(X_bow_dev, X_tfidf_dev, X_tfidf_f_dev, y_dev, test_size=0.1, stratify=y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that returns performance of classifier \n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "def classification_metrics(header_text, clf, X_train, X_test, y_train, y_test):\n",
    "    print(\"=\"*35)\n",
    "    print(\" \"*int((35-len(header_text))/2), header_text)\n",
    "    print(\"=\"*35)\n",
    "    y_pred = clf.predict(X_train)\n",
    "    print(\"Train Accuracy:\", accuracy_score(y_train, y_pred))\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"Val Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"F1 Score:\", f1_score(y_test, y_pred, average=\"weighted\"))\n",
    "    print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First a simple dummy classifier was tested using the bag of word counts. It predicts the class of the observation from the most frequent class in the set. This performs about as well as expected with a accuracy of 55.82% for both training and validation. This is also the case when adding the additional features as the most frequent class in the observed y does not change with additional features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================\n",
      "          Dummy classifier\n",
      "===================================\n",
      "Train Accuracy: 0.5582465277777777\n",
      "Val Accuracy: 0.558203125\n",
      "F1 Score: 0.3999359566934069\n",
      "[[   0 1382    0]\n",
      " [   0 4287    0]\n",
      " [   0 2011    0]]\n"
     ]
    }
   ],
   "source": [
    "# Dummy classifier predicting most frequent class\n",
    "from sklearn.dummy import DummyClassifier\n",
    "dummy = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy.fit(X_bow_train, y_train)\n",
    "y_pred = dummy.predict(X_bow_val)\n",
    "classification_metrics(\"Dummy classifier\", dummy, X_bow_train, X_bow_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the dummy classifier, the next step to test was the TF-IDF data. This was done using a logistic regression as that provides a discrete outcome. This performs significantly better than the dummy classifier with an accuracy of 65% on the validation set. When adding the extra features troubles arise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================\n",
      "      LogisticRegression tf-idf\n",
      "===================================\n",
      "Train Accuracy: 0.7214554398148149\n",
      "Val Accuracy: 0.64921875\n",
      "F1 Score: 0.6296259411112886\n",
      "[[ 505  818   59]\n",
      " [ 212 3607  468]\n",
      " [  30 1107  874]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(solver=\"saga\")\n",
    "lr.fit(X_tfidf_train, y_train)\n",
    "classification_metrics(\"LogisticRegression tf-idf\", lr, X_tfidf_train, X_tfidf_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================\n",
      "   LogisticRegression tf-idf full\n",
      "===================================\n",
      "Train Accuracy: 0.7216145833333333\n",
      "Val Accuracy: 0.64921875\n",
      "F1 Score: 0.6294342783846033\n",
      "[[ 504  818   60]\n",
      " [ 210 3611  466]\n",
      " [  29 1111  871]]\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(solver=\"saga\")\n",
    "lr.fit(X_tfidf_f_train, y_train)\n",
    "classification_metrics(\"LogisticRegression tf-idf full\", lr, X_tfidf_f_train, X_tfidf_f_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then xgboost is employed to see what a Gradient Boosting can do to classify the price points of the establishments. This does not perform better than the logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================\n",
      "           XGBoost tf-idf\n",
      "===================================\n",
      "Train Accuracy: 0.5934751157407407\n",
      "Val Accuracy: 0.58671875\n",
      "F1 Score: 0.47844368750126176\n",
      "[[ 130 1243    9]\n",
      " [  38 4190   59]\n",
      " [   5 1820  186]]\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "xgb = xgboost.XGBClassifier(eval_metric=\"mlogloss\", use_label_encoder=False)\n",
    "xgb.fit(X_tfidf_train, y_train)\n",
    "classification_metrics(\"XGBoost tf-idf\", xgb, X_tfidf_train, X_tfidf_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================\n",
      "         XGBoost tf-idf full\n",
      "===================================\n",
      "Train Accuracy: 0.5942708333333333\n",
      "Val Accuracy: 0.5859375\n",
      "F1 Score: 0.47892009874393476\n",
      "[[ 129 1247    6]\n",
      " [  44 4178   65]\n",
      " [   6 1812  193]]\n"
     ]
    }
   ],
   "source": [
    "xgb.fit(X_tfidf_f_train, y_train)\n",
    "classification_metrics(\"XGBoost tf-idf full\", xgb, X_tfidf_f_train, X_tfidf_f_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, as the Logistic regression seems to perform the best, an Ordinal Logistic Regression is tested. This could be useful as there is an inherent order to the price points in the sense that `$$` is more expensive than `$` etc. (`$` < `$$` < `$$$`) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================\n",
      " Ordinal Logistic Regression tf-idf\n",
      "===================================\n",
      "Train Accuracy: 0.783839699074074\n",
      "Val Accuracy: 0.558203125\n",
      "F1 Score: 0.3999359566934069\n",
      "[[   0 1382    0]\n",
      " [   0 4287    0]\n",
      " [   0 2011    0]]\n"
     ]
    }
   ],
   "source": [
    "from mord import LogisticAT\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# y must be integer - fixed in df \n",
    "#y_train = np.array([int(i) for i in y_train])\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "X_tfidf_train = scaler.fit_transform(X_tfidf_train)\n",
    "lat = LogisticAT(alpha=1.0, verbose=0)\n",
    "lat.fit(X_tfidf_train, y_train)\n",
    "classification_metrics(\"Ordinal Logistic Regression tf-idf\", lat, X_tfidf_train, X_tfidf_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================\n",
      " Ordinal Logistic Regression tf-idf full\n",
      "===================================\n",
      "Train Accuracy: 0.7839265046296297\n",
      "Val Accuracy: 0.558203125\n",
      "F1 Score: 0.3999359566934069\n",
      "[[   0 1382    0]\n",
      " [   0 4287    0]\n",
      " [   0 2011    0]]\n"
     ]
    }
   ],
   "source": [
    "X_tfidf_f_train = scaler.fit_transform(X_tfidf_f_train)\n",
    "lat.fit(X_tfidf_f_train, y_train)\n",
    "classification_metrics(\"Ordinal Logistic Regression tf-idf full\", lat, X_tfidf_f_train, X_tfidf_f_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As ordinal regression (as well as dummy and xgboost) performs significantly worse than the logistic regression, the logistic regression is chosen to be tuned in order to increase performance. This is done through a grid search to tune the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\tokeh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from scipy.stats import loguniform\n",
    "\n",
    "# As the goal is to classify, the RepeatedStratifiedKFold is used\n",
    "cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=3, random_state=1)\n",
    "\n",
    "space = dict()\n",
    "space['solver'] = ['saga']\n",
    "space['penalty'] = ['none', 'l1', 'l2']\n",
    "space['C'] = [0.1, 1, 10]\n",
    "\n",
    "search = GridSearchCV(lr, space, cv=cv)\n",
    "result = search.fit(X_tfidf_f_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The found hyperparameters can be seen below, and will be used for predicting the price points of the full data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.6408613040123456\n",
      "Best Hyperparameters: {'C': 1, 'penalty': 'l2', 'solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = bow_tfidf_full\n",
    "predict = lr.predict(X)\n",
    "# Get prices back to 1-2-3 format instead of 0-1-2\n",
    "df[\"pred_price\"] = predict+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7022531015301924"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fraction that matches real price\n",
    "sum(sum([df[\"price\"] == df[\"pred_price\"]])) / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First create a series with the Id, predicted price and the counts\n",
    "p_choice = df.groupby(['gPlusPlaceId', 'pred_price']).size()\n",
    "# Create dataframe\n",
    "df_p = p_choice.to_frame('count').reset_index()\n",
    "# Find largest count for each place Id\n",
    "df_pmax = df_p.groupby('gPlusPlaceId').max()['count'].reset_index()\n",
    "# Merge the largest count and the df with the price points\n",
    "df_pfin = df_pmax.merge(df_p, on=['gPlusPlaceId', 'count'])\n",
    "# Drop the counts\n",
    "df_pfin = df_pfin.drop(['count'], axis=1)\n",
    "# As there are cases where there are equal number of reviews, these cases pick the larger price\n",
    "df_pfin = df_pfin.groupby('gPlusPlaceId').max()['pred_price'].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df_pfin['pred_price'].value_counts())\n",
    "\n",
    "#df_pori = df.groupby('gPlusPlaceId').mean()['price'].reset_index()\n",
    "#print(df_pori['price'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the prices are added to the places data, such that every establishment has a price associated with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gPlusPlaceId</th>\n",
       "      <th>name</th>\n",
       "      <th>price</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>city</th>\n",
       "      <th>address</th>\n",
       "      <th>Grid</th>\n",
       "      <th>category</th>\n",
       "      <th>pred_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101742583391038750118</td>\n",
       "      <td>Carpo London</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.509499</td>\n",
       "      <td>-0.135762</td>\n",
       "      <td>London</td>\n",
       "      <td>16 Piccadilly, London W1J 0DE, United Kingdom</td>\n",
       "      <td>L159</td>\n",
       "      <td>Retail</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100574642292837870712</td>\n",
       "      <td>Premium Cars</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.514637</td>\n",
       "      <td>-0.064980</td>\n",
       "      <td>London</td>\n",
       "      <td>10 Commercial Road Premium Cars First Floor, S...</td>\n",
       "      <td>L186</td>\n",
       "      <td>Other</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>105185983265572241970</td>\n",
       "      <td>eSpares Ltd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.479416</td>\n",
       "      <td>-0.179209</td>\n",
       "      <td>London</td>\n",
       "      <td>Chelsea Wharf, 15 Lots Rd, London, Chelsea SW1...</td>\n",
       "      <td>L40</td>\n",
       "      <td>Wholesale</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104500852703501308358</td>\n",
       "      <td>Superdrug</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.494537</td>\n",
       "      <td>-0.145769</td>\n",
       "      <td>London</td>\n",
       "      <td>Unit 35, Victoria Railway Station, London SW1V...</td>\n",
       "      <td>L101</td>\n",
       "      <td>Retail</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>107519298595557659572</td>\n",
       "      <td>Kura</td>\n",
       "      <td>2.0</td>\n",
       "      <td>51.502122</td>\n",
       "      <td>-0.163029</td>\n",
       "      <td>London</td>\n",
       "      <td>3-4 Park Close, London SW1X 7PQ, United Kingdom</td>\n",
       "      <td>L137</td>\n",
       "      <td>Restaurant</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            gPlusPlaceId          name  price        lat       lon    city  \\\n",
       "0  101742583391038750118  Carpo London    NaN  51.509499 -0.135762  London   \n",
       "1  100574642292837870712  Premium Cars    NaN  51.514637 -0.064980  London   \n",
       "2  105185983265572241970   eSpares Ltd    NaN  51.479416 -0.179209  London   \n",
       "3  104500852703501308358     Superdrug    NaN  51.494537 -0.145769  London   \n",
       "4  107519298595557659572          Kura    2.0  51.502122 -0.163029  London   \n",
       "\n",
       "                                             address  Grid    category  \\\n",
       "0      16 Piccadilly, London W1J 0DE, United Kingdom  L159      Retail   \n",
       "1  10 Commercial Road Premium Cars First Floor, S...  L186       Other   \n",
       "2  Chelsea Wharf, 15 Lots Rd, London, Chelsea SW1...   L40   Wholesale   \n",
       "3  Unit 35, Victoria Railway Station, London SW1V...  L101      Retail   \n",
       "4    3-4 Park Close, London SW1X 7PQ, United Kingdom  L137  Restaurant   \n",
       "\n",
       "   pred_price  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         3.0  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_places = pd.read_csv(\"data/places_final.csv\")\n",
    "df_places = pd.merge(df_places, df_pfin, how=\"left\", on=\"gPlusPlaceId\")\n",
    "df_places.head()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6f9910882fae098898ae321f07726ec847ec186b3979568b9e6c54444f9aa773"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
