{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is downloaded from [Google Local](https://cseweb.ucsd.edu/~jmcauley/datasets.html#google_local) data published by Professor Julian McAuley from University of California, San Diego. The data contains reviews about businesses along with their geographical location. The raw data has 3.116.785 businesses and 11.453.845 reviews, which spans across locations all over the world.\n",
    "\n",
    "The data is stored as multiple non comma seperated dictionaries and must be converted into readable json format. This process in done below. The code takes approximate 6 hours to run and outputs the two data files \"reviews.csv\" and \"places.csv\". In this data downloading process, we have decided to only use data from United Kingdom and New York, USA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import gzip\n",
    "import shutil\n",
    "import json\n",
    "import re\n",
    "import ast\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "data_path = \"data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzipping and saving as json\n",
    "def unzip_gzip(file):\n",
    "    with gzip.open(file, \"rb\") as f_in:\n",
    "        with open(file.rsplit(\".\", 1)[0], \"wb\") as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify file path\n",
    "url = \"http://deepyeti.ucsd.edu/jmcauley/datasets/googlelocal/places.clean.json.gz\"\n",
    "filename = url.split(\"/\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download file\n",
    "with open(data_path + filename, \"wb\") as f:\n",
    "    r = requests.get(url)\n",
    "    f.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "unzip_gzip(data_path + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3114353it [04:42, 11020.28it/s]\n"
     ]
    }
   ],
   "source": [
    "# Inspiration from https://gist.github.com/mbrzusto/23fe728966247f25f3ec\n",
    "fr=open(data_path + \"places.clean.json\")\n",
    "fw=open(data_path + \"places.json\", \"w\")\n",
    "written_firstline = 0\n",
    "for line in tqdm(fr):\n",
    "    json_dat = ast.literal_eval(line)\n",
    "    full_address = \", \".join(json_dat['address'])\n",
    "    in_ny = re.findall(r\"NY\\s\\d{5}\", json_dat['address'][-1]) # addresses in New York end with NY XXXXX\n",
    "    in_london = re.findall(r'London.*?United Kingdom', full_address) # addresses in London contains the word London followed by zip code of varying length and United Kingdom\n",
    "    if in_ny or in_london:\n",
    "        if written_firstline == 0: # If file is empty\n",
    "            fw.write(\"[\")\n",
    "            json.dump(json_dat, fw)\n",
    "            written_firstline += 1\n",
    "        else:\n",
    "            fw.write(\",\\n\")\n",
    "            json.dump(json_dat, fw)\n",
    "fw.write(\"]\")\n",
    "\n",
    "fw.close()\n",
    "fr.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path + \"places.json\", \"r\") as f:\n",
    "    content = json.loads(f.read())\n",
    "\n",
    "df = pd.DataFrame(content)\n",
    "df.to_csv(data_path + \"places.csv\", index=False, sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`gPlusPlaceId` is a unique ID for each business."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102851, 8)\n",
      "102851\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.gPlusPlaceId.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "places = pd.read_csv(data_path + \"places.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://deepyeti.ucsd.edu/jmcauley/datasets/googlelocal/reviews.clean.json.gz\"\n",
    "filename = url.split(\"/\")[-1]\n",
    "with open(data_path + filename, \"wb\") as f:\n",
    "    r = requests.get(url)\n",
    "    f.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "unzip_gzip(data_path + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11453845it [7:45:05, 410.44it/s]\n"
     ]
    }
   ],
   "source": [
    "places_ids = places.gPlusPlaceId.values\n",
    "fr=open(data_path + \"reviews.clean.json\")\n",
    "fw=open(data_path + \"reviews.json\", \"w\")\n",
    "written_firstline = 0\n",
    "for line in tqdm(fr):\n",
    "    json_dat = ast.literal_eval(line)\n",
    "    if json_dat['gPlusPlaceId'] in places_ids:\n",
    "        if written_firstline == 0:\n",
    "            fw.write(\"[\")\n",
    "            json.dump(json_dat, fw)\n",
    "            written_firstline += 1\n",
    "        else:\n",
    "            fw.write(\",\\n\")\n",
    "            json.dump(json_dat, fw)\n",
    "                 \n",
    "fw.write(\"]\")\n",
    "\n",
    "fw.close()\n",
    "fr.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path + \"reviews.json\", \"r\") as f:\n",
    "    content = json.loads(f.read())\n",
    "\n",
    "df = pd.DataFrame(content)\n",
    "df.to_csv(data_path + \"reviews.csv\", index=False, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9e9e982dfc258e8d223c37f4327606c8da7dedee0f3f31349257777800bfa443"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
