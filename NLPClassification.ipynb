{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "data_path = \"data/\"\n",
    "places = pd.read_csv(data_path + \"places_final.csv\")\n",
    "reviews = pd.read_csv(data_path + \"reviews_final.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create copy of `reviews` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(reviews, places[[\"gPlusPlaceId\", \"price\"]], how=\"left\", on=\"gPlusPlaceId\")\n",
    "df.dropna(subset=[\"reviewTextClean\", \"price\"], inplace=True)\n",
    "df = df.loc[:, [\"price\", \"rating\", \"gPlusPlaceId\", \"reviewTextClean\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>rating</th>\n",
       "      <th>gPlusPlaceId</th>\n",
       "      <th>reviewTextClean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>106689630448064755324</td>\n",
       "      <td>cute hotel good amenity nice location great cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>108256990636148259283</td>\n",
       "      <td>love place massage facial technician best loun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>105947477166033397439</td>\n",
       "      <td>service amazing line go fast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>107098981103934500500</td>\n",
       "      <td>get chicken green salad yum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>108585910849109169666</td>\n",
       "      <td>never falafel bar yum super crunchy sweet pota...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257100</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>110548558285915713747</td>\n",
       "      <td>delicious pizza price good downfall amount peo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257102</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>107346748950819090586</td>\n",
       "      <td>went mole festival saturday night worst restau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257103</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>110403843200459675752</td>\n",
       "      <td>42nd street photo camera wa looking best price...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257106</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101421411984715145689</td>\n",
       "      <td>true life saver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257110</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>114598669582568454722</td>\n",
       "      <td>used better service horrible price good food s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96008 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        price  rating           gPlusPlaceId  \\\n",
       "0         3.0     3.0  106689630448064755324   \n",
       "1         3.0     4.0  108256990636148259283   \n",
       "6         2.0     5.0  105947477166033397439   \n",
       "7         1.0     5.0  107098981103934500500   \n",
       "8         1.0     5.0  108585910849109169666   \n",
       "...       ...     ...                    ...   \n",
       "257100    2.0     4.0  110548558285915713747   \n",
       "257102    3.0     1.0  107346748950819090586   \n",
       "257103    2.0     5.0  110403843200459675752   \n",
       "257106    1.0     4.0  101421411984715145689   \n",
       "257110    2.0     2.0  114598669582568454722   \n",
       "\n",
       "                                          reviewTextClean  \n",
       "0       cute hotel good amenity nice location great cr...  \n",
       "1       love place massage facial technician best loun...  \n",
       "6                            service amazing line go fast  \n",
       "7                             get chicken green salad yum  \n",
       "8       never falafel bar yum super crunchy sweet pota...  \n",
       "...                                                   ...  \n",
       "257100  delicious pizza price good downfall amount peo...  \n",
       "257102  went mole festival saturday night worst restau...  \n",
       "257103  42nd street photo camera wa looking best price...  \n",
       "257106                                    true life saver  \n",
       "257110  used better service horrible price good food s...  \n",
       "\n",
       "[96008 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create BoW representation of `reviewTextClean`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96008, 54767)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "bow_counts = count_vect.fit_transform(df['reviewTextClean'].values)\n",
    "bow_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary: 54767\n",
      "Length of corpus: 96008\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of vocabulary:\", len(count_vect.vocabulary_))\n",
    "print(\"Length of corpus:\", bow_counts.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create tf-idf representation of `reviewTextClean`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf = TfidfTransformer()\n",
    "bow_tfidf = tfidf.fit_transform(bow_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = df.price.values-1\n",
    "\n",
    "# Split into development and test split\n",
    "X_bow_dev, X_bow_test, X_tfidf_dev, X_tfidf_test, y_dev, y_test = train_test_split(bow_counts, bow_tfidf, y, test_size=0.2, stratify=y)\n",
    "\n",
    "# Split development into training and validation\n",
    "X_bow_train, X_bow_val, X_tfidf_train, X_tfidf_val, y_train, y_val = train_test_split(X_bow_dev, X_tfidf_dev, y_dev, test_size=0.1, stratify=y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "def classification_metrics(header_text, clf, X_train, X_test, y_train, y_test):\n",
    "    print(\"=\"*35)\n",
    "    print(\" \"*int((35-len(header_text))/2), header_text)\n",
    "    print(\"=\"*35)\n",
    "    y_pred = clf.predict(X_train)\n",
    "    print(\"Train Accuracy:\", accuracy_score(y_train, y_pred))\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"Val Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"F1 Score:\", f1_score(y_test, y_pred, average=\"weighted\"))\n",
    "    print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================\n",
      "          Dummy classifier\n",
      "===================================\n",
      "Train Accuracy: 0.558249547920434\n",
      "Val Accuracy: 0.5582606431454238\n",
      "F1 Score: 0.40000361564167053\n",
      "[[   0 1382    0]\n",
      " [   0 4288    0]\n",
      " [   0 2011    0]]\n"
     ]
    }
   ],
   "source": [
    "# Dummy classifier predicting most frequent class\n",
    "from sklearn.dummy import DummyClassifier\n",
    "dummy = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy.fit(X_bow_train, y_train)\n",
    "y_pred = dummy.predict(X_bow_val)\n",
    "classification_metrics(\"Dummy classifier\", dummy, X_bow_train, X_bow_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================\n",
      "       LogisticRegression BoW\n",
      "===================================\n",
      "Train Accuracy: 0.7251066907775768\n",
      "Val Accuracy: 0.6378075771383934\n",
      "F1 Score: 0.6151654448298587\n",
      "[[ 471  851   60]\n",
      " [ 241 3611  436]\n",
      " [  28 1166  817]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bruger\\Documents\\GoogleLocalReviews\\abaenv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(solver=\"saga\")\n",
    "lr.fit(X_bow_train, y_train)\n",
    "classification_metrics(\"LogisticRegression BoW\", lr, X_bow_train, X_bow_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================\n",
      "      LogisticRegression tf-idf\n",
      "===================================\n",
      "Train Accuracy: 0.7312839059674503\n",
      "Val Accuracy: 0.649654992839474\n",
      "F1 Score: 0.6289672961670463\n",
      "[[ 471  847   64]\n",
      " [ 224 3621  443]\n",
      " [  20 1093  898]]\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(solver=\"saga\")\n",
    "lr.fit(X_tfidf_train, y_train)\n",
    "classification_metrics(\"LogisticRegression tf-idf\", lr, X_tfidf_train, X_tfidf_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_tfidf_train, y_train)\n",
    "classification_metrics(\"RandomForest tf-idf\", rfc, X_tfidf_train, X_tfidf_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "xgb = xgboost.XGBClassifier(eval_metric=\"mlogloss\", use_label_encoder=False)\n",
    "xgb.fit(X_bow_train, y_train)\n",
    "classification_metrics(\"XGBoost BoW\", xgb, X_bow_train, X_bow_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================\n",
      "          XGBoost tf-idf\n",
      "===================================\n",
      "Train Accuracy: 0.6870596745027124\n",
      "Val Accuracy: 0.626220544199974\n",
      "F1 Score: 0.5770760772029238\n",
      "[[ 362  990   30]\n",
      " [ 134 3928  226]\n",
      " [  12 1479  520]]\n"
     ]
    }
   ],
   "source": [
    "xgb = xgboost.XGBClassifier(eval_metric=\"mlogloss\", use_label_encoder=False)\n",
    "xgb.fit(X_tfidf_train, y_train)\n",
    "classification_metrics(\"XGBoost tf-idf\", xgb, X_tfidf_train, X_tfidf_val, y_train, y_val)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6f9910882fae098898ae321f07726ec847ec186b3979568b9e6c54444f9aa773"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('abaenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
